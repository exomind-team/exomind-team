# 任务计划：从二轮小车感知到计算机生命的推演框架

> 创建时间：2026-01-12
> 目标：为1.12刘老师会议提供纸面推演，展示从二轮小车视觉/听觉到计算机生命的转化路径

---

## 1. 任务概述

### 1.1 核心目标
为刘老师的会议提供一个**纸上推演demo**，展示：
- 二轮小车的视觉或听觉感知如何映射到计算机生命框架
- 从传感器数据到"生命表征"的转化路径
- 验证计算机生命理论在具体场景下的可操作性

### 1.2 理论背景（已确认）
基于项目已有的核心文档：
- **否决式判据**：可存活区间、判断、失败不可回滚、边界
- **L1-L3三层架构**：基因/细胞层 → 组织/个体层 → 具身层
- **能量概念**：CPU时间片、存储空间、I/O预算

### 1.3 交付物要求
- 位置：`ExoMind-Team/Projects/计算机生命/ai-output/01-……`
- 形式：纸面推演demo（含示意图、流程图、案例分析）
- 深度：足以让刘老师判断可行性

---

## 2. 工作分解

### Phase 1：理论体系梳理（已完成）
- [x] 搜索并整理所有计算机生命相关文档
- [x] 提取核心观点和概念结构
- [x] 确认外部理论支撑（Tierra, Avida, 自创生理论）

**发现总结**：
- 项目已形成完整的理论-工程体系
- 核心创新：否决式判据 + TPM不可逆锚点
- 待验证：从感知数据到生命表征的转化路径

### Phase 2：构建推演框架（当前）
- [ ] **2.1 确定推演案例**：选择视觉或听觉作为切入点
- [ ] **2.2 建立映射关系**：传感器数据 → 计算机生命概念
- [ ] **2.3 设计推演流程**：从原始数据到"生命行为"的全链路
- [ ] **2.4 标注关键节点**：可存活区间、判断点、边界

### Phase 3：纸上demo设计
- [ ] **3.1 设计示意图**：L0-L3层级映射图
- [ ] **3.2 编写推演案例**：完整的从听到行动的流程
- [ ] **3.3 标注失败场景**：越界判定、死亡/伤疤机制
- [ ] **3.4 补充对比分析**：与现有方法的差异

### Phase 4：输出与整合
- [ ] **4.1 整理输出文档**：Markdown格式的完整推演报告
- [ ] **4.2 关联已有文档**：引用项目书、设计总结中的核心概念
- [ ] **4.3 生成可视化材料**：PlantUML图、流程图

---

## 3. 详细任务列表

### 3.1 案例选择决策

**选项A：听觉通道推演**
- 原始数据：音频频谱（频率-振幅-时间）
- 感知目标：识别特定音色（如"正向音"vs"负向音"）
- 生命转化：将频谱模式映射到"可食用资源"vs"威胁"

**选项B：视觉通道推演**
- 原始数据：摄像头图像序列
- 感知目标：识别特定颜色/形状（如"充电桩"vs"障碍物"）
- 生命转化：将视觉模式映射到"能量源"vs"边界威胁"

**推荐**：选择**听觉通道**，原因：
1. 数据结构更简洁（频谱 vs 像素矩阵）
2. 与会议讨论的"音色识别"直接对应
3. 更容易展示"感知→判断→行动"的快速环路

### 3.2 推演框架核心要素

```
L0 物理层（二轮小车）
├── 麦克风采集音频 → ADC转换 → 频谱分析
└── 电机控制信号 ← PWM输出

L1 感知层（信号处理）
├── 频段能量提取（子带滤波）
├── 时序模式检测（变化率/间隔）
└→ 输出：感知事件流 {类型, 强度, 可信度}

L2 判断层（计算机生命核心）
├── 可存活区间检查：能量预算、队列容量
├── 否决式判据：此感知是否威胁边界？
├── 行动选择：觅食/防御/休眠/繁殖
└→ 输出：裁决结果 {行动类型, 资源消耗}

L3 行动层（执行）
├── 运动控制：转向/速度调整
├── 资源获取：接近声源/远离威胁
└→ 状态更新：能量-步数, 伤疤+1

边界机制：
├── 膜通道：仅通过网关访问传感器数据
├── 红线变量：心跳超时、队列窒息、维护窗口
└→ 死亡条件：步数耗尽、边界破坏
```

### 3.3 纸上demo结构设计

**文档结构**：
1. **案例背景**（1段）：二轮小车 + 听觉感知场景
2. **层级映射图**（1图）：L0-L3四层映射关系
3. **推演流程**（3步）：
   - Step 1: 原始音频 → 感知事件
   - Step 2: 感知事件 → 判断裁决
   - Step 3: 裁决 → 行动 → 后果
4. **失败场景**（2例）：
   - 场景A：能量耗尽死亡
   - 场景B：边界破坏伤疤
5. **与传统方法对比**（1表）：vs CNN/Transformer

---

## 4. 关键决策点

| 决策项 | 选项 | 选择 |
|-------|------|-----|
| 案例类型 | 听觉 / 视觉 | **听觉**（更简洁） |
| 感知目标 | 音色识别 / 声源定位 | **音色识别**（对应"资源/威胁"二分） |
| 失败类型 | 步数耗尽 / 队列窒息 / 维护窗口错过 | **步数耗尽**（最直观） |
| 伤疤表现 | CPU配额下降 / 权限收缩 / 记忆丢失 | **CPU配额下降**（可量化） |

---

## 5. 依赖与风险

### 5.1 依赖
- 项目书中的理论框架（已完成）
- 会议记录中的具体需求（已完成）
- L1-L3架构定义（已完成）

### 5.2 风险
- **理论深度不足**：需要确保推演不偏离否决式判据核心
- **案例过于简化**：需平衡简洁性与理论完整性
- **时间紧迫**：需在会议前完成

### 5.3 应对策略
- 坚持使用项目书中的术语体系
- 每个步骤都标注对应的理论判据
- 提供"深入阅读"索引，便于刘老师追问

---

## 6. 验收标准

### 6.1 必须包含
- [ ] 从音频到行动的完整链路
- [ ] 可存活区间的具体定义（数值化）
- [ ] 否决式判据的应用示例
- [ ] 死亡/伤疤的触发条件
- [ ] 与传统方案的对比

### 6.2 加分项
- [ ] 多感知通道的并行处理示意
- [ ] 伤疤累积对感知能力的影响
- [ ] 繁殖/分裂的推演扩展

---

## 7. 后续扩展

本次纸上demo聚焦于**单个体感知-行动闭环**，为后续扩展奠定基础：
- 扩展A：多个体竞争与协作（生态层面）
- 扩展B：发育与分化（多细胞层面）
- 扩展C：从听觉扩展到视觉/触觉（多模态层面）

---

> 计划版本：v1.0
> 状态：待用户确认后执行
