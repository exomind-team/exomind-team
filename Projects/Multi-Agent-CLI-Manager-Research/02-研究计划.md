# Multi-Agent CLI Manager 研究计划

> 计划版本：v1.0
> 创建日期：2026年1月9日

## 一、研究目标

### 1.1 总体目标

通过系统性的调研和评估，为用户选择或自建多命令行 Agent 管理软件提供决策依据。

### 1.2 具体目标

1. **市场认知**：全面了解市场上现有的多 Agent 管理工具
2. **需求匹配**：评估现有工具与用户需求的匹配程度
3. **方案对比**：对比自建系统与使用现有方案的优劣势
4. **决策支持**：提供清晰的建议和实施路径

## 二、研究范围

### 2.1 工具范围

| 类别 | 重点调研工具 | 辅助了解工具 |
|------|-------------|-------------|
| 多 Agent 编排框架 | AutoGen、CrewAI、LangGraph | Magentic-One、AgentScope |
| AI 编程 CLI | Claude Code CLI、Gemini CLI | Aider、OpenCode |
| 多 Agent 管理看板 | Vibe Kanban、Aviator Runbooks | Kanboard |
| 规格驱动开发 | OpenSpec、Gatomia | MCP Server Spec-Driven |
| Agent 协议 | MCP、ACP、A2A | 厂商特定协议 |

### 2.2 评估维度

1. **功能完整性**：核心功能是否满足需求
2. **用户体验**：操作便捷性、学习成本
3. **技术架构**：可扩展性、稳定性、安全性
4. **社区活跃度**：文档、教程、问题响应
5. **成本分析**：许可费用、维护成本、迁移成本

## 三、研究方法

### 3.1 方法论

采用「定量与定性相结合」的研究方法：

1. **文献调研**：搜索和分析官方文档、技术博客、学术论文
2. **工具试用**：安装和体验关键工具的核心功能
3. **对比分析**：建立评估矩阵，进行系统性对比
4. **专家咨询**：参考社区讨论和技术文章的观点

### 3.2 数据来源

| 来源类型 | 具体来源 | 用途 |
|---------|---------|------|
| 官方文档 | GitHub README、官方网站 | 功能确认 |
| 技术博客 | CSDN、博客园、掘金、知乎 | 使用体验 |
| 社区讨论 | GitHub Issues、Reddit、Discord | 问题发现 |
| 学术资源 | arXiv、ResearchGate | 理论背景 |

## 四、执行计划

### 4.1 第一阶段：信息收集（已完成）

**时间**：2026年1月9日

**任务**：
- [x] 搜索多 Agent CLI 管理工具
- [x] 搜索 vibe-kanban 相关软件
- [x] 搜索规格驱动开发工具
- [x] 收集 AI Agent 框架信息
- [x] 获取工具官方文档

**交付物**：
- 搜索结果汇总
- 初步工具列表（15+ 工具）

### 4.2 第二阶段：详细调研（进行中）

**时间**：2026年1月9日 - 2026年1月16日

**任务**：
- [ ] **工具分类整理**（1天）
  - 按功能分类整理工具列表
  - 标记每个工具的核心特点
  - 建立工具档案

- [ ] **重点工具深度调研**（3天）
  - Vibe Kanban：完整功能测试
  - OpenSpec：安装和使用体验
  - Aviator Runbooks：功能探索
  - Claude Code CLI：核心功能试用

- [ ] **次要工具快速评估**（2天）
  - AutoGen：快速上手体验
  - CrewAI：功能概览
  - LangGraph：架构分析
  - Gemini CLI：对比测试

- [ ] **用户需求验证**（1天）
  - 对照用户需求评估工具
  - 标记满足/不满足/部分满足
  - 识别差距和机会

**交付物**：
- 工具分类清单
- 重点工具评测报告
- 需求匹配度分析

### 4.3 第三阶段：方案对比

**时间**：2026年1月17日 - 2026年1月23日

**任务**：
- [ ] **现有方案评估**（3天）
  - 详细对比各工具的功能
  - 评估安装和配置复杂度
  - 测试实际使用体验
  - 编写现有方案评估报告

- [ ] **自建方案分析**（2天）
  - 分析自建系统的可行性
  - 估算开发成本和时间
  - 评估技术风险
  - 编写自建方案分析报告

- [ ] **成本效益分析**（2天）
  - 对比各方案的总拥有成本（TCO）
  - 评估收益和风险
  - 制作成本对比表格

**交付物**：
- 现有方案评估报告
- 自建方案分析报告
- 成本效益分析

### 4.4 第四阶段：报告撰写

**时间**：2026年1月24日 - 2026年1月30日

**任务**：
- [ ] **综合报告撰写**（4天）
  - 整理所有研究发现
  - 撰写综述报告
  - 编写附录和参考资料

- [ ] **决策建议**（1天）
  - 提供清晰的决策建议
  - 给出推荐方案
  - 制定实施路线图

- [ ] **评审和修订**（1天）
  - 内部评审
  - 修订和完善报告

**交付物**：
- 最终综述报告（01-综述报告.md）
- 工具对比分析（03-工具对比分析.md）
- 需求分析（04-需求分析.md）
- 可行性评估（05-可行性评估.md）

## 五、详细任务分解

### 5.1 工具评测清单

| 工具名称 | 评测优先级 | 评测内容 | 预计时间 |
|---------|-----------|---------|----------|
| Vibe Kanban | P0 | 完整功能测试 | 4小时 |
| OpenSpec | P0 | 安装和使用体验 | 3小时 |
| Claude Code CLI | P0 | 核心功能试用 | 3小时 |
| Aviator Runbooks | P1 | 功能探索 | 2小时 |
| Gemini CLI | P1 | 对比测试 | 2小时 |
| AutoGen | P1 | 快速上手 | 2小时 |
| CrewAI | P2 | 功能概览 | 1小时 |
| LangGraph | P2 | 架构分析 | 2小时 |
| Aider | P2 | 对比了解 | 1小时 |

### 5.2 评估指标体系

| 指标类别 | 具体指标 | 权重 | 评分标准 |
|---------|---------|------|----------|
| 功能性（40%） | 多窗口管理 | 15% | 1-5分 |
| | 进度跟踪 | 10% | 1-5分 |
| | 通知机制 | 8% | 1-5分 |
| | 规格驱动 | 7% | 1-5分 |
| 可用性（25%） | 安装配置 | 8% | 1-5分 |
| | 学习成本 | 9% | 1-5分 |
| | 操作便捷 | 8% | 1-5分 |
| 技术性（20%） | 架构设计 | 10% | 1-5分 |
| | 扩展性 | 10% | 1-5分 |
| 生态（15%） | 社区活跃 | 8% | 1-5分 |
| | 文档完善 | 7% | 1-5分 |

## 六、资源需求

### 6.1 工具资源

| 资源类型 | 具体需求 | 用途 |
|---------|---------|------|
| Node.js 18+ | 运行 Vibe Kanban | 工具测试 |
| Python 3.10+ | 运行 AutoGen、CrewAI | 框架测试 |
| Git | 版本控制 | 代码获取 |
| 终端模拟器 | 多窗口测试 | 使用体验 |

### 6.2 外部服务

| 服务 | 用途 | 成本 |
|-----|------|------|
| Claude API | Claude Code 测试 | 按量计费 |
| Google AI Studio | Gemini CLI 测试 | 免费 |
| GitHub | 代码仓库访问 | 免费 |

## 七、风险识别与应对

| 风险 | 影响 | 应对措施 |
|-----|------|----------|
| 部分工具需要 API Key | 无法完整测试 | 申请试用或使用免费版本 |
| 工具更新频繁 | 信息过时 | 标注调研日期，注明版本 |
| 测试环境差异 | 结果不准确 | 记录测试环境，注明限制 |
| 用户需求变化 | 研究方向偏离 | 定期与用户确认需求 |

## 八、里程碑

| 里程碑 | 目标 | 预计完成时间 |
|-------|------|-------------|
| M1 | 信息收集完成 | 2026-01-09 |
| M2 | 重点工具评测完成 | 2026-01-16 |
| M3 | 方案对比完成 | 2026-01-23 |
| M4 | 报告初稿完成 | 2026-01-28 |
| M5 | 最终报告交付 | 2026-01-30 |

## 九、后续行动建议

### 9.1 短期行动（报告完成后）

1. **决策会议**：与用户一起评审报告，确定方向
2. **试用验证**：根据建议的工具进行深度试用
3. **POC 测试**：如需要，进行概念验证测试

### 9.2 中期行动（1-2个月）

1. **工具选型**：确定最终使用的工具
2. **环境搭建**：配置开发和使用环境
3. **流程整合**：将工具整合到现有工作流程

### 9.3 长期行动（3-6个月）

1. **效果评估**：评估工具的实际效果
2. **优化调整**：根据使用体验进行优化
3. **能力扩展**：如有需要，开发定制功能

## 十、附录

### 10.1 术语表

| 术语 | 定义 |
|-----|------|
| Agent | 智能代理，能够自主执行任务的 AI 程序 |
| Multi-Agent | 多智能体，多个 Agent 协同工作 |
| Orchestration | 编排，协调和管理多个 Agent 的工作 |
| Spec-Driven | 规格驱动，先定义规格再执行开发 |
| MCP | Model Context Protocol，模型上下文协议 |
| CLI | Command Line Interface，命令行界面 |

### 10.2 参考资料

详见 01-综述报告.md 中的参考资料部分

---

**计划作者**：Claude Code
**计划版本**：v1.0
**最后更新**：2026年1月9日
